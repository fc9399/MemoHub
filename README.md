# üß† **Project Title: MemoHub**

**Tagline:** *Empowering AI Agents with Long-Term, Multi-Modal Memory ‚Äî Built on NVIDIA NIM + AWS*

---

## üö© **Overview**

**MemoHub** is a multi-modal **memory engine** that transforms your everyday experiences ‚Äî text, voice, images, and documents ‚Äî into an evolving, structured stream of knowledge.
By organizing these "memory units" in a semantic graph, it provides **AI agents with long-term recall and reasoning capabilities**, enabling them to understand not only *what* you said, but *when*, *why*, and *in what context*.

Our vision: to bridge human-like memory and AI cognition through a unified system that can *remember, relate, and reason* over time ‚Äî powered by **NVIDIA NIM** and **AWS infrastructure**.

---

## üí° **Problem**

Most AI assistants today have **short-term memory** ‚Äî they forget prior interactions, lose context, and can't build upon previous experiences.
Humans, by contrast, continuously integrate information from **multiple modalities** (speech, images, text, meetings).
This creates a cognitive gap between human memory and AI reasoning.

### Challenges we address

* Fragmented data across formats and platforms
* Lack of persistent, contextual AI memory
* Inefficient retrieval and reasoning over accumulated knowledge

---

## üöÄ **Solution**

**MemoHub** continuously collects and organizes multi-modal inputs into a **unified "memory stream"**, stored as structured **memory cells** with semantic metadata.

Each memory cell encodes:

* Content embeddings (text, image, audio transcripts)
* Context (timestamp, source, relational links)
* Summaries and topics for fast retrieval

During conversations or reasoning tasks, the **AI Agent** retrieves and reasons over related memory clusters using **NVIDIA NIM microservices**, allowing it to:

* Recall past events and visual cues
* Draw inferences based on long-term context
* Adapt dynamically through continuous learning

This transforms an agent from a reactive chatbot into a **cognitive, context-aware system** capable of reasoning over its own history.

---

## üèÜ **AWS & NVIDIA Hackathon Requirements**

This project fully complies with all hackathon requirements:

### ‚úÖ Required Components Implemented

| Requirement | Implementation | Status |
|------------|----------------|---------|
| **LLM Reasoning Model** | NVIDIA NIM `llama-3.1-nemotron-nano-8B-v1` deployed as microservice | ‚úÖ Implemented |
| **Retrieval Embedding NIM** | NVIDIA `llama-3.2-nv-embedqa-1b-v2` for semantic search | ‚úÖ Implemented |
| **Deployment Platform** | Amazon EKS Cluster with GPU-enabled node groups (g5.2xlarge) | ‚úÖ Implemented |
| **Agentic AI Application** | Memory-driven AI agent with RAG and multi-step reasoning | ‚úÖ Implemented |

### üîß Technical Stack Alignment

* **NVIDIA NIM LLM Service**: Containerized `llama-3.1-nemotron-nano-8B-v1` on EKS for intelligent dialogue and reasoning
* **NVIDIA Retrieval NIM**: Embedding model for vector generation and semantic retrieval
* **AWS EKS**: Kubernetes orchestration with GPU node pools for scalable inference
* **AWS Services**: DynamoDB (memory metadata), S3 (file storage), EC2 (GPU compute)
* **Agentic Framework**: LangChain + custom orchestration for memory-augmented reasoning

---

## ‚öôÔ∏è **Technical Architecture**

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (Next.js)                            ‚îÇ
‚îÇ              Upload / Search / Organize / Chat                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                FastAPI Gateway (AWS EKS)                         ‚îÇ
‚îÇ           Auth / API Keys / Uploads / Query Router              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                        ‚îÇ
            ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Agentic Layer     ‚îÇ    ‚îÇ      NVIDIA NIM Services (EKS)       ‚îÇ
‚îÇ   - Curator Agent   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§  - LLM NIM (llama-3.1-nemotron)     ‚îÇ
‚îÇ   - Retriever Agent ‚îÇ    ‚îÇ  - Embedding NIM (nv-embedqa)        ‚îÇ
‚îÇ   - Organizer Agent ‚îÇ    ‚îÇ  - Vision NIM (optional)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Data Layer (AWS)                            ‚îÇ
‚îÇ  - DynamoDB (metadata + vectors)  - S3 (files)                  ‚îÇ
‚îÇ  - PostgreSQL + pgvector (optional graph storage)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Architecture Layers

| Layer | Description | Technologies |
|-------|-------------|--------------|
| **Frontend Dashboard** | User interface for upload, search, organization, and AI chat | Next.js, TailwindCSS, Zustand |
| **API Gateway** | FastAPI orchestration, authentication, routing, file handling | FastAPI, JWT Auth, AWS EKS |
| **Agentic AI Layer** | **Core Innovation**: Memory-driven agents with multi-step reasoning using **llama-3.1-nemotron-nano-8B-v1 NIM** | NVIDIA NIM LLM, LangChain Agents, Custom Orchestration |
| **Retrieval & Embedding** | Semantic search and vector generation via **Retrieval Embedding NIM** | **NVIDIA NIM** `llama-3.2-nv-embedqa-1b-v2`, Cosine Similarity |
| **Memory Storage** | Structured memory units with embeddings, metadata, and relationships | AWS DynamoDB (vectors + metadata), PostgreSQL + pgvector |
| **File Storage** | Multi-modal file storage (PDFs, images, documents, audio) | AWS S3 with lifecycle policies |
| **Deployment Infrastructure** | **AWS EKS** cluster with NVIDIA GPU nodes for NIM workloads | Amazon EKS, EC2 g5.2xlarge instances, NVIDIA GPU Operator |

### Key Workflows

#### 1. **Upload Workflow**
```
User Upload ‚Üí File Type Check ‚Üí S3 Storage ‚Üí 
Multi-Modal Parser ‚Üí Text Extraction ‚Üí 
Embedding Generation (NIM) ‚Üí DynamoDB Storage ‚Üí 
Memory Index Update
```

#### 2. **Search Workflow**
```
User Query ‚Üí Query Embedding (NIM) ‚Üí 
Semantic Search (Cosine Similarity) ‚Üí 
Ranking & Filtering ‚Üí Result Return
```

#### 3. **AI Conversation Workflow**
```
User Question ‚Üí Search Related Memory (Retriever Agent) ‚Üí 
Context Building ‚Üí LLM Reasoning (NIM) ‚Üí 
Response Generation ‚Üí Memory Update
```

---

## üß© **Key Features**

1. üéôÔ∏è **Multi-Modal Capture** ‚Äì Upload or record voice, images, PDFs, or text to build a continuous knowledge timeline.
2. üß† **Long-Term Memory Agent** ‚Äì AI recalls user-specific sessions, entities, and preferences across conversations.
3. üîç **Semantic Search & Q/A** ‚Äì Ask *"What insights did I discuss in last week's meeting?"* and get contextual answers.
4. ü§ñ **Agentic Reasoning** ‚Äì Multi-agent system orchestrates retrieval, context building, and intelligent response generation.
5. üîÅ **Continuous Learning Loop** ‚Äì New interactions strengthen or reshape existing memory nodes, inspired by human cognition.
6. üîê **User Authentication** ‚Äì Secure JWT-based authentication with API key management for external integrations.
7. üåê **API Access** ‚Äì RESTful API allows external LLMs and applications to query user memories.

---

## ‚ö° **Innovation**

* **Native NVIDIA NIM Integration**: Built from the ground up on NVIDIA NIM microservices for both embeddings and LLM inference
* **Memory-Augmented Agentic AI**: Goes beyond simple RAG ‚Äì implements multi-agent orchestration with memory consolidation
* **Scalable GPU Infrastructure**: Deployed on AWS EKS with auto-scaling GPU node groups for cost-effective inference
* **Multi-Modal Processing**: Handles text, PDFs, images, and audio transcripts in a unified memory stream
* **Memory Consolidation**: Mimics human memory by prioritizing relevant experiences while allowing others to fade
* **Production-Ready Architecture**: Full deployment pipeline with Kubernetes, Helm charts, and monitoring

---

## üåç **Impact**

* **For Individuals:** A personal AI memory companion that never forgets ‚Äî enabling deep contextual assistance across time and providing continuity in AI interactions.
* **For Teams:** A shared, searchable knowledge stream that captures conversations, notes, and visual data ‚Äî becoming an institutional memory.
* **For AI Agents:** A foundation for genuine *contextual intelligence* ‚Äî transforming reactive chatbots into cognitive systems with memory-driven reasoning and decision-making.
* **For Developers:** An API-first architecture allowing external LLMs to leverage user memories through secure, rate-limited access.

---

## üöÄ **Deployment**

### Development Environment
- NVIDIA API endpoints for rapid prototyping
- Local DynamoDB and S3 simulation

### Production Environment (AWS EKS)
- NVIDIA NIM containers deployed on GPU-enabled EKS nodes
- Auto-scaling based on inference load
- Multi-AZ deployment for high availability
- CloudWatch monitoring and logging
- Complete Kubernetes manifests and Helm charts included

**See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed deployment instructions.**

---

## üìö **Documentation**

- **[DEPLOYMENT.md](DEPLOYMENT.md)**: Complete deployment guide for AWS EKS with NVIDIA NIM
- **[API Documentation](http://localhost:8000/docs)**: Interactive Swagger UI with all endpoints
- **Architecture Diagrams**: System and workflow visualizations included in repository

---

## üîó **Repository Structure**

```
MemoHub/
‚îú‚îÄ‚îÄ main.py                 # FastAPI application entry point
‚îú‚îÄ‚îÄ routers/                # API route handlers
‚îÇ   ‚îú‚îÄ‚îÄ upload.py          # File upload endpoints
‚îÇ   ‚îú‚îÄ‚îÄ search.py          # Semantic search APIs
‚îÇ   ‚îú‚îÄ‚îÄ ai_agent.py        # AI chat and reasoning
‚îÇ   ‚îî‚îÄ‚îÄ auth.py            # Authentication
‚îú‚îÄ‚îÄ services/               # Core business logic
‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py   # NVIDIA NIM embedding integration
‚îÇ   ‚îú‚îÄ‚îÄ llm_service.py         # NVIDIA NIM LLM integration
‚îÇ   ‚îú‚îÄ‚îÄ database_service.py    # DynamoDB operations
‚îÇ   ‚îî‚îÄ‚îÄ ai_agent_service.py    # Agentic orchestration
‚îú‚îÄ‚îÄ UI/memohub/             # Next.js frontend
‚îú‚îÄ‚îÄ DEPLOYMENT.md           # AWS EKS deployment guide
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îî‚îÄ‚îÄ README.md              # This file
```

---

## üèÅ **In Summary**

> **MemoHub** transforms scattered experiences into a living knowledge fabric ‚Äî empowering AI agents to remember, reason, and evolve.
>
> Built with **NVIDIA NIM microservices** (`llama-3.1-nemotron-nano-8B-v1` for reasoning, `llama-3.2-nv-embedqa-1b-v2` for embeddings) and deployed on **AWS EKS** with GPU acceleration for scalable, production-grade agentic AI.

---

## üèÜ **AWS & NVIDIA Hackathon Submission**

This project represents a complete implementation of an Agentic AI application meeting all hackathon requirements:
- ‚úÖ Uses `llama-3.1-nemotron-nano-8B-v1` as LLM reasoning model
- ‚úÖ Implements Retrieval Embedding NIM for semantic search
- ‚úÖ Deployed on AWS EKS with GPU node groups
- ‚úÖ Demonstrates practical value with memory-driven AI interactions
- ‚úÖ Production-ready with authentication, API management, and monitoring

**Demo Video**: [(https://youtu.be/0-zydyh3uoE)]  
**GitHub Repository**: [(https://github.com/fc9399/MemoHub)]

## üôè **Credits & Acknowledgments**

### Team Members
- **[Yunlan Qiao]** - Lead Developer, Frontend Architecture
- **[Lin Jia]** - AI/ML Engineering, NIM Integration, Backend Architecture
- **[Fung Chau]** - Backend Development, Testing

---

**Built with ‚ù§Ô∏è for the AWS & NVIDIA Hackathon 2025**
